@article{chawla_accurate_realtime_2018,
  title = {An Accurate Real-Time {{RFID-based}} Location System},
  author = {Chawla, Kirti and McFarland, Christopher and Robins, Gabriel and Thomason, Wil},
  date = {2018-01},
  journaltitle = {International Journal of Radio Frequency Identification Technology and Applications},
  shortjournal = {Int. J. Radio Freq. Identif. Technol. Appl.},
  volume = {5},
  number = {1},
  pages = {48--76},
  publisher = {{Inderscience Publishers}},
  doi = {10.1504/IJRFITA.2018.091306},
  url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJRFITA.2018.091306},
  abstract = {Modern applications frequently require the ability to locate objects in real-world environments. This has motivated the development of a number of competing approaches to object localisation, most of which target specific applications. Radio Frequency IDentification (RFID) has emerged as a viable platform for localisation, but due to a number of unresolved challenges with this technology, high levels of performance and wide applicability have remained elusive. In this paper, we outline an RFID-based object localisation framework that addresses these challenges, and propose the use of Received Signal Strength (RSS) to model the behaviour of radio signals decaying over distance in an orientation-agnostic manner to simultaneously locate multiple stationary and mobile objects. The proposed localisation system can operate in a realistically radio-noisy indoor environment, enables design-space trade-offs, is highly extensible, and provides use-case-driven average accuracy as low as 0.15 metres. The proposed localisation system can quickly locate objects with or without the use of reference tags, and illustrates that RSS can be a reliable metric for RFID-based object localisation.},
  keywords = {empirical power-distance relationship,localisation,RFID,RSS,tag-reader pairs}
}
% == BibLateX quality report for chawla_accurate_realtime_2018:
% Unexpected field 'publisher'
% ? unused ISSN ("1745-3216")
% ? unused Library catalog ("inderscienceonline.com (Atypon)")

@inproceedings{lee_object_reconfiguration_2023,
  title = {Object {{Reconfiguration}} with {{Simulation-Derived Feasible Actions}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lee, Yiyuan and Thomason, Wil and Kingston, Zachary and Kavraki, Lydia E.},
  date = {2023-05},
  pages = {8104--8111},
  doi = {10.1109/ICRA48891.2023.10160377},
  url = {https://ieeexplore.ieee.org/document/10160377},
  abstract = {3D object reconfiguration encompasses common robot manipulation tasks in which a set of objects must be moved through a series of physically feasible state changes into a desired final configuration. Object reconfiguration is challenging to solve in general, as it requires efficient reasoning about environment physics that determine action validity. This information is typically manually encoded in an explicit transition system. Constructing these explicit encodings is tedious and error-prone, and is often a bottleneck for planner use. In this work, we explore embedding a physics simulator within a motion planner to implicitly discover and specify the valid actions from any state, removing the need for manual specification of action semantics. Our experiments demonstrate that the resulting simulation-based planner can effectively produce physically valid rearrangement trajectories for a range of 3D object reconfiguration problems without requiring more than an environment description and start and goal arrangements.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  file = {/home/wil/Zotero/storage/MU7YYXHP/lee_object_reconfiguration_2023.pdf;/home/wil/Zotero/storage/QMKL9LEC/10160377.html}
}
% == BibLateX quality report for lee_object_reconfiguration_2023:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("IEEE Xplore")

@inproceedings{mavrogiannis_social_momentum_2018,
  title = {Social {{Momentum}}: {{A Framework}} for {{Legible Navigation}} in {{Dynamic Multi-Agent Environments}}},
  shorttitle = {Social {{Momentum}}},
  booktitle = {2018 13th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}} ({{HRI}})},
  author = {Mavrogiannis, Christoforos I. and Thomason, Wil B. and Knepper, Ross A.},
  date = {2018-03},
  pages = {361--369},
  url = {https://ieeexplore.ieee.org/document/9473631},
  abstract = {Intent-expressive robot motion has been shown to result in increased efficiency and reduced planning efforts for copresent humans. Existing frameworks for generating intent-expressive robot behaviors have typically focused on applications in static or structured environments. Under such settings, emphasis is placed towards communicating the robot’s intended final configuration to other agents. However, in dynamic, unstructured and multi-agent domains, such as pedestrian environments, knowledge of the robot’s final configuration is not sufficiently informative as it completely ignores the complex dynamics of interaction among agents. To address this problem, we design a planning framework that aims at generating motion that clearly communicates an agent’s intended collision avoidance strategy rather than its destination. Our framework estimates the most likely intended avoidance protocols of others based on their past behaviors, superimposes them, and generates an expressive and socially compliant robot action that reinforces the expectations of others regarding these avoidance protocols. This action facilitates inference and decision making for everyone, as illustrated in the simplified topological pattern of agents’ trajectories. Extensive simulations demonstrate that our framework consistently achieves significantly lower topological complexity, compared against common benchmark approaches in multi-agent collision avoidance. The significance of this result for real world applications is demonstrated by a user study that reveals statistical evidence suggesting that multi-agent trajectories of lower topological complexity tend to facilitate inference for observers.},
  eventtitle = {2018 13th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}} ({{HRI}})},
  file = {/home/wil/Zotero/storage/C5CJENXR/9473631.html}
}
% == BibLateX quality report for mavrogiannis_social_momentum_2018:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused ISSN ("2167-2148")
% ? unused Library catalog ("IEEE Xplore")

@article{mavrogiannis_social_momentum_2022,
  title = {Social {{Momentum}}: {{Design}} and {{Evaluation}} of a {{Framework}} for {{Socially Competent Robot Navigation}}},
  shorttitle = {Social {{Momentum}}},
  author = {Mavrogiannis, Christoforos and Alves-Oliveira, Patrícia and Thomason, Wil and Knepper, Ross A.},
  date = {2022-02-08},
  journaltitle = {ACM Transactions on Human-Robot Interaction},
  shortjournal = {J. Hum.-Robot Interact.},
  volume = {11},
  number = {2},
  pages = {14:1--14:37},
  doi = {10.1145/3495244},
  url = {https://dl.acm.org/doi/10.1145/3495244},
  abstract = {Mobile robots struggle to integrate seamlessly in crowded environments such as pedestrian scenes, often disrupting human activity. One obstacle preventing their smooth integration is our limited understanding of how humans may perceive and react to robot motion. Motivated by recent studies highlighting the benefits of intent-expressive motion for robots operating close to humans, we describe Social Momentum (SM), a planning framework for legible robot motion generation in multiagent domains. We investigate the properties of motion generated by SM via two large-scale user studies: an online, video-based study (N = 180) focusing on the legibility of motion produced by SM and a lab study (N = 105) focusing on the perceptions of users navigating next to a robot running SM in a crowded space. Through statistical and thematic analyses of collected data, we present evidence suggesting that (a) motion generated by SM enables quick inference of the robot’s navigation strategy; (b) humans navigating close to a robot running SM follow comfortable, low-acceleration paths; and (c) robot motion generated by SM is positively perceived and indistinguishable from a teleoperated baseline. Through the discussion of experimental insights and lessons learned, this article aspires to inform future algorithmic and experimental design for social robot navigation.},
  keywords = {benchmarking,multiagent systems,Social navigation,social robotics},
  file = {/home/wil/Zotero/storage/EFEVLQFS/mavrogiannis_social_momentum_2022.pdf}
}
% == BibLateX quality report for mavrogiannis_social_momentum_2022:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("ACM Digital Library")

@article{thomason_counterexampleguided_repair_2023,
  title = {Counterexample-{{Guided Repair}} for {{Symbolic-Geometric Action Abstractions}}},
  author = {Thomason, Wil and Kress-Gazit, Hadas},
  date = {2023},
  journaltitle = {IEEE Transactions on Robotics},
  shortjournal = {IEEE Trans. Robot.},
  pages = {1--14},
  doi = {10.1109/TRO.2023.3294918},
  url = {https://ieeexplore.ieee.org/document/10214189},
  abstract = {Integrated task and motion planning (TMP) offers a promising class of approaches for solving robot planning problems with intricate symbolic and geometric constraints. However, TMP planners rely on difficult-to-construct abstract models of robot actions. In this article, we propose a method for automatically constructing and continuously improving an abstraction of robot actions via observations of the robot performing the actions. This method, called automatic abstraction repair, allows action abstractions to be initially incorrect or incomplete and converge toward a correct model over time. Here, we demonstrate abstraction repair using constrained polynomial zonotopes (CPZs), an expressive nonconvex set representation for modeling predicates over joint symbolic and geometric state. The repair process performs a hybrid optimizing search over symbolic edit operations to predicate formulae and continuous predicate parameters to improve the grounding of the abstraction to the behavior of a physical robot. In this work, we describe the predicate model, introduce the symbolic-geometric abstraction repair problem, and present an anytime algorithm for automatic abstraction repair. We demonstrate that abstraction repair can improve realistic action abstractions for common mobile manipulation actions from a handful of observations and discuss the tradeoffs of the CPZ model for predicate representation.},
  eventtitle = {{{IEEE Transactions}} on {{Robotics}}},
  file = {/home/wil/Zotero/storage/VN2JPLRN/thomason_counterexampleguided_repair_2023a.pdf;/home/wil/Zotero/storage/TVW29WIL/10214189.html}
}
% == BibLateX quality report for thomason_counterexampleguided_repair_2023:
% Unexpected field 'eventtitle'
% ? Title looks like it was stored in title-case in Zotero
% ? unused ISSN ("1941-0468")
% ? unused Library catalog ("IEEE Xplore")

@inproceedings{thomason_recognizing_unfamiliar_2017,
  title = {Recognizing {{Unfamiliar Gestures}} for {{Human-Robot Interaction Through Zero-Shot Learning}}},
  booktitle = {2016 {{International Symposium}} on {{Experimental Robotics}}},
  author = {Thomason, Wil and Knepper, Ross A.},
  editor = {Kulić, Dana and Nakamura, Yoshihiko and Khatib, Oussama and Venture, Gentiane},
  date = {2017},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {841--852},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-50115-4_73},
  url = {https://wbthomason.github.io/papers/iser2016_unfamiliargestures.pdf},
  abstract = {Human communication is highly multimodal, including speech, gesture, gaze, facial expressions, and body language. Robots serving as human teammates must act on such multimodal communicative inputs from humans, even when the message may not be clear from any single modality. In this paper, we explore a method for achieving increased understanding of complex, situated communications by leveraging coordinated natural language, gesture, and context. These three problems have largely been treated separately, but unified consideration of them can yield gains in comprehension~[1, 12].},
  langid = {english},
  keywords = {Human Teammates,Understandable Gesture,Unfamiliar Gestures,Word Embedding Space,Zero-shot Learning},
  file = {/home/wil/Zotero/storage/XKE4IHD5/thomason_recognizing_unfamiliar_2016.pdf}
}
% == BibLateX quality report for thomason_recognizing_unfamiliar_2017:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused ISBN ("978-3-319-50115-4")
% ? unused Library catalog ("Springer Link")

@article{thomason_task_motion_2022,
  title = {Task and {{Motion Informed Trees}} ({{TMIT}}*): {{Almost-Surely Asymptotically Optimal Integrated Task}} and {{Motion Planning}}},
  shorttitle = {Task and {{Motion Informed Trees}} ({{TMIT}}*)},
  author = {Thomason, Wil and Strub, Marlin P. and Gammell, Jonathan D.},
  date = {2022-10},
  journaltitle = {IEEE Robotics and Automation Letters},
  shortjournal = {IEEE Robot. Autom. Lett.},
  volume = {7},
  number = {4},
  pages = {11370--11377},
  doi = {10.1109/LRA.2022.3199676},
  url = {https://ieeexplore.ieee.org/document/9869707},
  abstract = {High-level autonomy requires discrete and continuous reasoning to decide both what actions to take and how to execute them. Integrated Task and Motion Planning (TMP) algorithms solve these hybrid problems jointly to consider constraints between the discrete symbolic actions (i.e., the task plan) and their continuous geometric realization (i.e., motion plans). This joint approach solves more difficult problems than approaches that address the task and motion subproblems independently. TMP algorithms combine and extend results from both task and motion planning. TMP has mainly focused on computational performance and completeness and less on solution optimality. Optimal TMP is difficult because the independent optima of the subproblems may not be the optimal integrated solution, which can only be found by jointly optimizing both plans. This letter presents Task and Motion Informed Trees (TMIT*), an optimal TMP algorithm that combines results from makespan-optimal task planning and almost-surely asymptotically optimal motion planning. TMIT* interleaves asymmetric forward and reverse searches to delay computationally expensive operations until necessary and perform an efficient informed search directly in the problem's hybrid state space. This allows it to solve problems quickly and then converge towards the optimal solution with additional computational time, as demonstrated on the evaluated robotic-manipulation benchmark problems.},
  eventtitle = {{{IEEE Robotics}} and {{Automation Letters}}},
  file = {/home/wil/Zotero/storage/ST7XWRZW/thomason_task_motion_2022a.pdf;/home/wil/Zotero/storage/XFC8ZG3L/9869707.html}
}
% == BibLateX quality report for thomason_task_motion_2022:
% Unexpected field 'eventtitle'
% ? Title looks like it was stored in title-case in Zotero
% ? unused ISSN ("2377-3766")
% ? unused Library catalog ("IEEE Xplore")

@inproceedings{thomason_unified_samplingbased_2022,
  title = {A {{Unified Sampling-Based Approach}} to {{Integrated Task}} and {{Motion Planning}}},
  booktitle = {Robotics {{Research}}},
  author = {Thomason, Wil and Knepper, Ross A.},
  editor = {Asfour, Tamim and Yoshida, Eiichi and Park, Jaeheung and Christensen, Henrik and Khatib, Oussama},
  date = {2022},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {773--788},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-95459-8_47},
  url = {https://wbthomason.github.io/papers/isrr2019_unifiedtamp.pdf},
  abstract = {We present a novel method for performing integrated task and motion planning (TMP) by adapting any off-the-shelf sampling-based motion planning algorithm to simultaneously solve for a symbolically and geometrically feasible plan using a single motion planner invocation. The core insight of our technique is an embedding of symbolic state into continuous space, coupled with a novel means of automatically deriving a function guiding a planner to regions of continuous space where symbolic actions can be executed. Our technique makes few assumptions and offers a great degree of flexibility and generality compared to state of the art planners. We describe our technique and offer a proof of probabilistic completeness along with empirical evaluation of our technique on manipulation benchmark problems.},
  langid = {english}
}
% == BibLateX quality report for thomason_unified_samplingbased_2022:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused ISBN ("978-3-030-95459-8")
% ? unused Library catalog ("Springer Link")
